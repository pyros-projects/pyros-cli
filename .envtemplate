# ============================================================================
# Model Configuration
# ============================================================================
# Flock supports all litellm-compatible models, including OpenAI and Azure OpenAI.
# Documentation: https://docs.litellm.ai/docs/providers
# Common models:

# AZURE - "azure/{model_name}"

; AZURE_API_KEY=xxx
; AZURE_API_BASE=https://xxx-foundry.cognitiveservices.azure.com/
; AZURE_API_VERSION="2024-12-01-preview"
; DEFAULT_MODEL="azure/gtp-4.1"

# OPENAI - "openai/{model_name}"

; OPENAI_API_KEY=xxx
; OPENAI_API_BASE=https://api.openai.com/v1/
; DEFAULT_MODEL="openai/gpt-5"

# OPENROUTER - "openrouter/{model_name}"

; OPENROUTER_API_KEY=
; OPENROUTER_API_BASE=
; DEFAULT_MODEL="openrouter/polaris-alpha"


# OPENAI_API_KEY=xxx


# ============================================================================
# Local Mode Configuration (pyros-local)
# ============================================================================
# Run completely offline using local models - no ComfyUI or cloud APIs needed!
# Install local dependencies: pip install pyros-cli[local]

# Local LLM for prompt enhancement and variable generation
# Default: Qwen/Qwen3-4B-Instruct-2507 (auto-downloads from HuggingFace)
; QWEN_4B_PATH=/path/to/local/qwen3-4b

# Local image generation model
# Default: Tongyi-MAI/Z-Image-Turbo (auto-downloads from HuggingFace)
; Z_IMAGE_PATH=/path/to/local/z-image

# Output directory for generated images
; LOCAL_OUTPUT_DIR=./output
